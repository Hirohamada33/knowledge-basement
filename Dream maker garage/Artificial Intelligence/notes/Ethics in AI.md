Seven Characteristics of AI Systems that might engender trust:
1. **Explainability**: AI system that can explain its decisions. Explanations must be understandable by the user. See XAI (Explainable AI) Research
2. **Auditability**: when something goes wrong, we need to be able to work out what happened. Equivalent to the black box on planes?
3. **Robustness**: An AI system is robust if it is capable of dealing with perturbations to their inputs.
4. **Correctness**: assurances the system will act ‘correctly’. E.g. safe bounds that will never be passed.
5. **Fairness**: are the results computed by the AI system “fair”?
6. **Respect for Privacy**: where does the data come from? Is that ok to train the ML algorithm with it?
7. **Transparency**: Transparency can help engender trust. However, transparency itself does not necessarily engender trust. There are also pitfalls to being transparent.

